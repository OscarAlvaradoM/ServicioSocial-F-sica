{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We would like to thanks the financial support of PAPIIT-IA104720"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face recognition using CNN\n",
    "\n",
    "- Óscar A. Alvarado\n",
    "- Oscar A. Esquivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mActivating\u001b[22m\u001b[39m environment at `C:\\Users\\Óscar Alvarado\\.julia\\environments\\CNN\\Project.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "#Pkg.activate(\"/home/oscar/.julia/environments/CNN\")\n",
    "Pkg.activate(\"C:/Users/Óscar Alvarado/.julia/environments/CNN\") # To use the correct environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Flux [587475ba-b771-5e3f-ad9e-33799f191a9c]\n",
      "└ @ Base loading.jl:1273\n",
      "┌ Warning: NNPACK not available for your platform: Windows(x86_64-w64-mingw32-libgfortran4-cxx11)\n",
      "│         You will be able to use only the default Julia NNlib backend\n",
      "└ @ NNlib C:\\Users\\Óscar Alvarado\\.julia\\packages\\NNlib\\sSn9M\\src\\NNlib.jl:14\n",
      "ERROR: LoadError: InitError: base64 binary data: Y291bGQgbm90IGxvYWQgbGlicmFyeSAiQzpcVXNlcnNc03NjYXIgQWx2YXJhZG9cQXBwRGF0YVxMb2NhbFxKdWxpYS0xLjMuMVxiaW5cTExWTS5kbGwiCgpTdGFja3RyYWNlOgogWzFdIA==\n",
      "dlopen at D:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.3\\Libdl\\src\\Libdl.jl:109 [inlined] (repeats 2 times)\n",
      " [2] (::LLVM.var\"#14#cache_fptr!#3\")() at C:\\Users\\Óscar Alvarado\\.julia\\packages\\LLVM\\KITdB\\src\\util.jl:103\n",
      " [3] macro expansion at C:\\Users\\Óscar Alvarado\\.julia\\packages\\LLVM\\KITdB\\src\\util.jl:111 [inlined]\n",
      " [4] runtime_version() at C:\\Users\\Óscar Alvarado\\.julia\\packages\\LLVM\\KITdB\\src\\base.jl:9\n",
      " [5] __init__() at C:\\Users\\Óscar Alvarado\\.julia\\packages\\LLVM\\KITdB\\src\\LLVM.jl:77\n",
      " [6] top-level scope at none:2\n",
      "during initialization of module LLVM\n",
      "in expression starting at C:\\Users\\Óscar Alvarado\\.julia\\packages\\GPUCompiler\\4e9CU\\src\\GPUCompiler.jl:3\n",
      "ERROR: LoadError: Failed to precompile GPUCompiler [61eb1bfa-7361-4325-ad38-22787b887f55] to C:\\Users\\Óscar Alvarado\\.julia\\compiled\\v1.3\\GPUCompiler\\yPwef_waEHw.ji.\n",
      "Stacktrace:\n",
      " [1] top-level scope at none:2\n",
      "in expression starting at C:\\Users\\Óscar Alvarado\\.julia\\packages\\CUDA\\42B9G\\src\\CUDA.jl:3\n",
      "ERROR: LoadError: Failed to precompile CUDA [052768ef-5323-5732-b1bb-66c8b64840ba] to C:\\Users\\Óscar Alvarado\\.julia\\compiled\\v1.3\\CUDA\\oWw5k_waEHw.ji.\n",
      "Stacktrace:\n",
      " [1] top-level scope at none:2\n",
      "in expression starting at C:\\Users\\Óscar Alvarado\\.julia\\packages\\Flux\\IjMZL\\src\\Flux.jl:29\n"
     ]
    },
    {
     "ename": "ErrorException",
     "evalue": "Failed to precompile Flux [587475ba-b771-5e3f-ad9e-33799f191a9c] to C:\\Users\\Óscar Alvarado\\.julia\\compiled\\v1.3\\Flux\\QdkVy_waEHw.ji.",
     "output_type": "error",
     "traceback": [
      "Failed to precompile Flux [587475ba-b771-5e3f-ad9e-33799f191a9c] to C:\\Users\\Óscar Alvarado\\.julia\\compiled\\v1.3\\Flux\\QdkVy_waEHw.ji.",
      "",
      "Stacktrace:",
      " [1] compilecache(::Base.PkgId, ::String) at .\\loading.jl:1283",
      " [2] _require(::Base.PkgId) at .\\loading.jl:1024",
      " [3] require(::Base.PkgId) at .\\loading.jl:922",
      " [4] require(::Module, ::Symbol) at .\\loading.jl:917",
      " [5] top-level scope at In[5]:2"
     ]
    }
   ],
   "source": [
    "using Images, ImageFeatures # We have to Pkg.add(\"Netpbm\") because our images are in pgm format\n",
    "using Flux\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: partition\n",
    "using Printf, BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m BSON ─ v0.2.6\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `C:\\Users\\Óscar Alvarado\\.julia\\environments\\CNN\\Project.toml`\n",
      " \u001b[90m [fbb218c0]\u001b[39m\u001b[92m + BSON v0.2.6\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `C:\\Users\\Óscar Alvarado\\.julia\\environments\\CNN\\Manifest.toml`\n",
      " \u001b[90m [fbb218c0]\u001b[39m\u001b[92m + BSON v0.2.6\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"BSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arc = 28\n",
    "\n",
    "train_imgs = []\n",
    "train_labels = []\n",
    "path_train = \"/almac/oscar_aam/Yale/CroppedYale$(arc)/train/\"\n",
    "for directory = readdir(path_train)\n",
    "    for file = readdir(path_train*directory)\n",
    "        #println(path_train*directory*\"/\"*file, directory[end-1:end])\n",
    "        push!(train_imgs, Float64.(load(path_train*directory*\"/\"*file)))\n",
    "        label = Meta.parse(directory[end-1:end])\n",
    "        if label < 14\n",
    "            push!(train_labels, label)\n",
    "        else\n",
    "            push!(train_labels, label-1)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "test_imgs = []\n",
    "test_labels = []\n",
    "path_train = \"/almac/oscar_aam/Yale/CroppedYale$(arc)/test/\"\n",
    "for directory = readdir(path_train)\n",
    "    for file = readdir(path_train*directory)\n",
    "        push!(test_imgs, Float64.(load(path_train*directory*\"/\"*file)))\n",
    "        label = Meta.parse(directory[end-1:end])\n",
    "        if label < 14\n",
    "            push!(test_labels, label)\n",
    "        else\n",
    "            push!(test_labels, label-1)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Building the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "# See: https://github.com/FluxML/model-zoo/blob/master/vision/mnist/conv.jl\n",
    "imgsize = (arc, arc, 1)\n",
    "cnn_output_size = Int.(floor.([imgsize[1]/8,imgsize[2]/8,32]))\n",
    "model = Chain(\n",
    "    # First convolution, operating upon a 192×192image\n",
    "    Conv((3, 3), 1=>16, pad=(1,1), relu),\n",
    "    MaxPool((2,2)), #maxpooling\n",
    "\n",
    "    # Second convolution, operating upon a 96×96 image\n",
    "    Conv((3, 3), 16=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)), #maxpooling\n",
    "\n",
    "    # Third convolution, operating upon a 48×48 image\n",
    "    Conv((3, 3), 32=>32,pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "\n",
    "    # Reshape 3d tensor into a 2d one, at this point it should be (24, 24, 32, N)\n",
    "    # which is where we get the 18432 in the `Dense` layer below:\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(prod(cnn_output_size), 38),\n",
    "\n",
    "    # Softmax to get probabilities\n",
    "    softmax,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching \n",
    "# See: https://github.com/FluxML/model-zoo/blob/master/vision/mnist/conv.jl\n",
    "# Bundle images together with labels and group into minibatchess\n",
    "function make_minibatch(X, Y, idxs, labels)\n",
    "    X_batch = Array{Float32}(undef, size(X[1])..., 1, length(idxs))\n",
    "    for i in 1:length(idxs)\n",
    "        X_batch[:, :, :, i] = Float32.(X[idxs[i]])\n",
    "    end\n",
    "    Y_batch = onehotbatch(Y[idxs], labels)\n",
    "    return (X_batch, Y_batch)\n",
    "end\n",
    "# The CNN only \"sees\" 128 images at each training cycle:\n",
    "batch_size = 128\n",
    "mb_idxs = partition(1:length(train_imgs), batch_size)\n",
    "# train set in the form of batches\n",
    "train_set = [make_minibatch(train_imgs, train_labels, i, 1:38) for i in mb_idxs];\n",
    "# train set in one-go: used to calculate accuracy with the train set\n",
    "train_set_full = make_minibatch(train_imgs, train_labels, 1:length(train_imgs), 1:38);\n",
    "# test set: to check we do not overfit the train data:\n",
    "test_set = make_minibatch(test_imgs, test_labels, 1:length(test_imgs), 1:38);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "# See: https://github.com/FluxML/model-zoo/blob/master/vision/mnist/conv.jl\n",
    "# `loss()` calculates the crossentropy loss between our prediction `y_hat`\n",
    "function loss(x, y)\n",
    "    # Add some noise to the image\n",
    "    # we reduce the risk of overfitting the train sample by doing so:\n",
    "    x_aug = x .+ 0.1f0*randn(eltype(x), size(x))\n",
    "\n",
    "    y_hat = model(x_aug)\n",
    "    return crossentropy(y_hat, y)\n",
    "end\n",
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))\n",
    "\n",
    "# ADAM optimizer\n",
    "opt = ADAM(0.001);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "# See: https://github.com/FluxML/model-zoo/blob/master/vision/mnist/conv.jl\n",
    "best_acc = 0.0\n",
    "last_improvement = 0\n",
    "accuracy_target = 0.95  #Set an accuracy target. When reached, we stop training.\n",
    "max_epochs = 200 #Maximum\n",
    "for epoch_idx in 1:max_epochs\n",
    "    global best_acc, last_improvement\n",
    "    # Train for a single epoch\n",
    "    println(\"Epoch $(epoch_idx)\")\n",
    "    @btime Flux.train!(loss, Flux.params(model), train_set, opt) \n",
    "\n",
    "    # Calculate accuracy:\n",
    "    acc = accuracy(train_set_full...)\n",
    "    @info(@sprintf(\"[%d]: Train accuracy: %.4f\", epoch_idx, acc))\n",
    "    \n",
    "    # Calculate accuracy:\n",
    "    acc = accuracy(test_set...)\n",
    "    @info(@sprintf(\"[%d]: Test accuracy: %.4f\", epoch_idx, acc))\n",
    "\n",
    "    # If our accuracy is good enough, quit out.\n",
    "    if acc >= accuracy_target\n",
    "        @info(\" -> Early-exiting: We reached our target accuracy of $(accuracy_target*100)%\")\n",
    "        @show epoch_idx\n",
    "        break\n",
    "    end\n",
    "\n",
    "    if epoch_idx - last_improvement >= max_epochs\n",
    "        @warn(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end\n",
    "\n",
    "# Get predictions and convert data to Array: \n",
    "pred = model(test_set[1]); \n",
    "\n",
    "# Function to get the row index of the max value: \n",
    "f1(x) = getindex.(argmax(x, dims=1), 1) # Final predicted value is the one with the maximum probability: \n",
    "pred = f1(pred); #minus 1, because the first digit is 0 (not 1)\n",
    "\n",
    "println(\"Predicted value = $(pred[1])\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
